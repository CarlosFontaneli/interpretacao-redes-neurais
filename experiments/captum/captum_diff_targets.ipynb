{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "\n",
    "from captum.attr import visualization as viz\n",
    "from captum.attr import LayerGradCam, FeatureAblation, LayerActivation, LayerAttribution\n",
    "\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default device plus free memory\n",
    "torch.cuda.empty_cache()\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fonta42/anaconda3/envs/torchtrainer/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/fonta42/anaconda3/envs/torchtrainer/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_MobileNet_V3_Large_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "fcn_model = models.segmentation.deeplabv3_mobilenet_v3_large(pretrained=True).to(device).eval()\n",
    "\n",
    "# Input preprocessing transformation\n",
    "preprocessing = transforms.Compose([transforms.Resize(640), \n",
    "                                    transforms.ToTensor()])\n",
    "normalize = transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-08 14:26:20 URL:https://farm8.staticflickr.com/7301/8862358875_eecba9fb10_z.jpg [110427] -> \"img/segmentation/8862358875_eecba9fb10_z.jpg.20\" [1]\n"
     ]
    }
   ],
   "source": [
    "# Get a image from the dataset\n",
    "!wget -nv --directory-prefix=img/segmentation/ https://farm8.staticflickr.com/7301/8862358875_eecba9fb10_z.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 640, 966])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open(\"img/segmentation/8862358875_eecba9fb10_z.jpg\")\n",
    "preproc_img = preprocessing(img)\n",
    "preproc_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize image and compute segmentation output\n",
    "normalized_inp = normalize(preproc_img).unsqueeze(0).to(device)\n",
    "normalized_inp.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper_pix(inp, p_height = 263, p_width = 705):\n",
    "    model_out = fcn_model(inp)['out']\n",
    "    return (model_out[0:1, :, p_height, p_width])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradcam for layers\n",
    "layer_gradcam = LayerGradCam(wrapper_pix, fcn_model.backbone['1'].block[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"background\",\n",
    "    \"aeroplane\",\n",
    "    \"bicycle\",\n",
    "    \"bird\",\n",
    "    \"boat\",\n",
    "    \"bottle\",\n",
    "    \"bus\",\n",
    "    \"car\",\n",
    "    \"cat\",\n",
    "    \"chair\",\n",
    "    \"cow\",\n",
    "    \"dining table\",\n",
    "    \"dog\",\n",
    "    \"horse\",\n",
    "    \"motorbike\",\n",
    "    \"person\",\n",
    "    \"potted plant\",\n",
    "    \"sheep\",\n",
    "    \"sofa\",\n",
    "    \"train\",\n",
    "    \"tv_monitor\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10052/4104997671.py:14: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"facecolor\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  _ = plt.savefig(f'./GradCamMaps/ByClass/{classes[j]}_gradcam_map.png')\n",
      "/tmp/ipykernel_10052/4104997671.py:14: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"edgecolor\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  _ = plt.savefig(f'./GradCamMaps/ByClass/{classes[j]}_gradcam_map.png')\n",
      "/tmp/ipykernel_10052/4104997671.py:14: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"orientation\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  _ = plt.savefig(f'./GradCamMaps/ByClass/{classes[j]}_gradcam_map.png')\n",
      "/tmp/ipykernel_10052/4104997671.py:14: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"bbox_inches_restore\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  _ = plt.savefig(f'./GradCamMaps/ByClass/{classes[j]}_gradcam_map.png')\n"
     ]
    }
   ],
   "source": [
    "for j in range(1, 21):\n",
    "  gradcam_attr = layer_gradcam.attribute(normalized_inp, \n",
    "                                    target=j, \n",
    "                                    attr_dim_summation=False).detach().cpu()\n",
    "\n",
    "  avrg_array = gradcam_attr.abs().mean(dim=(2,3))[0]\n",
    "  idx = torch.argsort(avrg_array, descending=True)\n",
    "\n",
    "  plt.figure(figsize=[25, 25])\n",
    "  for i in range(16):\n",
    "    plt.subplot(5,5, i + 1)\n",
    "    _ = plt.imshow(gradcam_attr[0, idx[i]].numpy(), cmap='RdBu')\n",
    "  \n",
    "  _ = plt.savefig(f'./GradCamMaps/ByClass/{classes[j]}_gradcam_map.png')\n",
    "  plt.close()\n",
    "  \n",
    "  # Default device plus free memory\n",
    "  torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_pixels(patch_width, patch_height, random_pixels):\n",
    "    # Image dimensions\n",
    "    height = 966\n",
    "    width = 640\n",
    "\n",
    "    # Calculate the number of patches along width and height\n",
    "    num_patches_width = width // patch_width\n",
    "    num_patches_height = height // patch_height\n",
    "\n",
    "    # Iterate through the patches\n",
    "    for i in range(num_patches_height):\n",
    "        for j in range(num_patches_width):\n",
    "            # Define the coordinates of the patch (left, upper, right, lower)\n",
    "            left = j * patch_width\n",
    "            upper = i * patch_height\n",
    "            right = (j + 1) * patch_width\n",
    "            lower = (i + 1) * patch_height\n",
    "\n",
    "            # Generate random x and y coordinates within the patch\n",
    "            x = random.randint(left, right - 1)\n",
    "            y = random.randint(upper, lower - 1)\n",
    "\n",
    "            # Add the pixel value to the list\n",
    "            random_pixels.append((x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper_pix(inp):\n",
    "      model_out = fcn_model(inp)['out']\n",
    "      return (model_out[0:1, :, 400, 400])\n",
    "    \n",
    "# Gradcam for layers\n",
    "layer_gradcam = LayerGradCam(wrapper_pix, fcn_model.backbone['1'].block[0][0])\n",
    "\n",
    "\n",
    "gradcam_attr = layer_gradcam.attribute(normalized_inp, \n",
    "                                  target=j, \n",
    "                                  attr_dim_summation=False).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8370/1177441920.py:24: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"facecolor\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  _ = plt.savefig(f'./GradCamMaps/ByPixels/x_{random_pixels[k][1]}_y_{random_pixels[k][0]}_gradcam_map.png')\n",
      "/tmp/ipykernel_8370/1177441920.py:24: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"edgecolor\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  _ = plt.savefig(f'./GradCamMaps/ByPixels/x_{random_pixels[k][1]}_y_{random_pixels[k][0]}_gradcam_map.png')\n",
      "/tmp/ipykernel_8370/1177441920.py:24: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"orientation\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  _ = plt.savefig(f'./GradCamMaps/ByPixels/x_{random_pixels[k][1]}_y_{random_pixels[k][0]}_gradcam_map.png')\n",
      "/tmp/ipykernel_8370/1177441920.py:24: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"bbox_inches_restore\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  _ = plt.savefig(f'./GradCamMaps/ByPixels/x_{random_pixels[k][1]}_y_{random_pixels[k][0]}_gradcam_map.png')\n"
     ]
    }
   ],
   "source": [
    "random_pixels = []\n",
    "generate_random_pixels(100, 100, random_pixels)\n",
    "for k in range(len(random_pixels)):\n",
    "  def wrapper_pix(inp):\n",
    "      model_out = fcn_model(inp)['out']\n",
    "      return (model_out[0:1, :, random_pixels[k][0], random_pixels[k][1]])\n",
    "    \n",
    "  # Gradcam for layers\n",
    "  layer_gradcam = LayerGradCam(wrapper_pix, fcn_model.backbone['1'].block[0][0])\n",
    "\n",
    "\n",
    "  gradcam_attr = layer_gradcam.attribute(normalized_inp, \n",
    "                                    target=j, \n",
    "                                    attr_dim_summation=False).detach().cpu()\n",
    "\n",
    "  avrg_array = gradcam_attr.abs().mean(dim=(2,3))[0]\n",
    "  idx = torch.argsort(avrg_array, descending=True)\n",
    "\n",
    "  plt.figure(figsize=[25, 25])\n",
    "  for i in range(9):\n",
    "    plt.subplot(3,3, i + 1)\n",
    "    _ = plt.imshow(gradcam_attr[0, idx[i]].numpy(), cmap='RdBu')\n",
    "  \n",
    "  _ = plt.savefig(f'./GradCamMaps/ByPixels/x_{random_pixels[k][1]}_y_{random_pixels[k][0]}_gradcam_map.png')\n",
    "  plt.close()\n",
    "  \n",
    "  # Default device plus free memory\n",
    "  torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6036/1764326342.py:25: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"facecolor\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  _ = plt.savefig(f'./GradCamMaps/ByClassesPixels/{classes[j]}/x_{random_pixels[k][1]}_y_{random_pixels[k][0]}_gradcam_map.png')\n",
      "/tmp/ipykernel_6036/1764326342.py:25: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"edgecolor\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  _ = plt.savefig(f'./GradCamMaps/ByClassesPixels/{classes[j]}/x_{random_pixels[k][1]}_y_{random_pixels[k][0]}_gradcam_map.png')\n",
      "/tmp/ipykernel_6036/1764326342.py:25: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"orientation\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  _ = plt.savefig(f'./GradCamMaps/ByClassesPixels/{classes[j]}/x_{random_pixels[k][1]}_y_{random_pixels[k][0]}_gradcam_map.png')\n",
      "/tmp/ipykernel_6036/1764326342.py:25: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"bbox_inches_restore\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  _ = plt.savefig(f'./GradCamMaps/ByClassesPixels/{classes[j]}/x_{random_pixels[k][1]}_y_{random_pixels[k][0]}_gradcam_map.png')\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "random_pixels = []\n",
    "generate_random_pixels(200, 200, random_pixels)\n",
    "for k in range(len(random_pixels)):\n",
    "  def wrapper_pix(inp):\n",
    "      model_out = fcn_model(inp)['out']\n",
    "      return (model_out[0:1, :, random_pixels[k][0], random_pixels[k][1]])\n",
    "    \n",
    "  # Gradcam for layers\n",
    "  layer_gradcam = LayerGradCam(wrapper_pix, fcn_model.backbone['1'].block[0][0])\n",
    "\n",
    "  for j in range(1, 21):\n",
    "    gradcam_attr = layer_gradcam.attribute(normalized_inp, \n",
    "                                           target=j, \n",
    "                                           attr_dim_summation=False).detach().cpu()\n",
    "\n",
    "    avrg_array = gradcam_attr.abs().mean(dim=(2,3))[0]\n",
    "    idx = torch.argsort(avrg_array, descending=True)\n",
    "\n",
    "    plt.figure(figsize=[25, 25])\n",
    "    for i in range(16):\n",
    "      ax = plt.subplot(4,4, i + 1)\n",
    "      ax.imshow(gradcam_attr[0, idx[i]].numpy(), cmap='RdBu')\n",
    "\n",
    "    os.makedirs(f'./GradCamMaps/ByClassesPixels/{classes[j]}', exist_ok=True)\n",
    "    _ = plt.savefig(f'./GradCamMaps/ByClassesPixels/{classes[j]}/x_{random_pixels[k][1]}_y_{random_pixels[k][0]}_gradcam_map.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Default device plus free memory\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10052/1826561659.py:33: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"facecolor\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  _ = plt.savefig(f'./GradCamMaps/ByPixelsClasses/x_{random_pixels[k][1]}_y_{random_pixels[k][0]}_gradcam_map.png')\n",
      "/tmp/ipykernel_10052/1826561659.py:33: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"edgecolor\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  _ = plt.savefig(f'./GradCamMaps/ByPixelsClasses/x_{random_pixels[k][1]}_y_{random_pixels[k][0]}_gradcam_map.png')\n",
      "/tmp/ipykernel_10052/1826561659.py:33: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"orientation\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  _ = plt.savefig(f'./GradCamMaps/ByPixelsClasses/x_{random_pixels[k][1]}_y_{random_pixels[k][0]}_gradcam_map.png')\n",
      "/tmp/ipykernel_10052/1826561659.py:33: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"bbox_inches_restore\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  _ = plt.savefig(f'./GradCamMaps/ByPixelsClasses/x_{random_pixels[k][1]}_y_{random_pixels[k][0]}_gradcam_map.png')\n"
     ]
    }
   ],
   "source": [
    "random_pixels = []\n",
    "generate_random_pixels(200, 200, random_pixels)\n",
    "for k in range(len(random_pixels)):\n",
    "  def wrapper_pix(inp):\n",
    "      model_out = fcn_model(inp)['out']\n",
    "      return (model_out[0:1, :, random_pixels[k][0], random_pixels[k][1]])\n",
    "    \n",
    "  # Gradcam for layers\n",
    "  layer_gradcam = LayerGradCam(wrapper_pix, fcn_model.backbone['1'].block[0][0])\n",
    "\n",
    "  #plt.figure(figsize=[25, 25])\n",
    "  maps = []\n",
    "  for j in range(1, 21):\n",
    "    gradcam_attr = layer_gradcam.attribute(normalized_inp, \n",
    "                                           target=j, \n",
    "                                           attr_dim_summation=False).detach().cpu()\n",
    "\n",
    "    avrg_array = gradcam_attr.abs().mean(dim=(2,3))[0]\n",
    "    idx = torch.argsort(avrg_array, descending=True)\n",
    "\n",
    "    for i in range(5):\n",
    "      maps.append(gradcam_attr[0, idx[i]].numpy())\n",
    "  \n",
    "  plt.figure(figsize=[30, 60])\n",
    "  for z in range(100):\n",
    "    ax = plt.subplot(20, 5, z + 1)\n",
    "    ax.grid(False)\n",
    "    ax.imshow(maps[z], cmap='RdBu')\n",
    "    #TODO: plt.plot then scatter with coordinates\n",
    "    ax.set_title(f'{classes[z // 5 + 1]}')\n",
    "\n",
    "  plt.tight_layout()\n",
    "  _ = plt.savefig(f'./GradCamMaps/ByPixelsClasses/x_{random_pixels[k][1]}_y_{random_pixels[k][0]}_gradcam_map.png')\n",
    "  plt.close()\n",
    "\n",
    "  # Default device plus free memory\n",
    "  torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchtrainer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
