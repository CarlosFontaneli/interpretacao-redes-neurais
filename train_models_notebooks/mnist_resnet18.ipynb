{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "import matplotlib.pyplot as plt\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "- Resized to 224x224 pixels. This is because the ResNet-18 model was originally designed for ImageNet (which consists of 224x224 images).\n",
    "\n",
    "- Converted to tensors, and their pixel values are scaled between [0, 1].\n",
    "\n",
    "- Normalized with a mean and standard deviation of 0.5. This step is crucial to ensure that the values of the input tensor are roughly on the same scale. Typically, for full RGB images, the mean and std of the ImageNet dataset would be used, but for grayscale images like MNIST, a single channel value is provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply resize and normalization to the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading:\n",
    "\n",
    "The code uses torchvision.datasets to load MNIST, a dataset of hand-written digits. The DataLoader constructs mini-batches automatically. These mini-batches are used in training and testing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Modification:\n",
    "\n",
    "By default, ResNet-18 expects a 3-channel (RGB) image of size 224x224. MNIST images are 1-channel images of size 28x28. The following modifications are done:\n",
    "\n",
    "- The first layer of ResNet-18 (model.conv1) is changed to accept a 1-channel input.\n",
    "\n",
    "- The final layer (model.fc) has its out_features set to 10, because there are 10 classes in MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fonta42/anaconda3/envs/torchtrainer/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/fonta42/anaconda3/envs/torchtrainer/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Modify ResNet-18 for MNIST\n",
    "model = resnet18(pretrained=False)\n",
    "# Change the input layer to accept grayscale images\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "# Adjust the final layer to output 10 classes\n",
    "model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "\n",
    "# Moving to GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics Storage:\n",
    "\n",
    "During both training and evaluation, the code computes and stores loss and accuracy for later visualization. This is done using the train_losses, train_accuracies, test_losses, and test_accuracies lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to store metrics\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function and Optimizer:\n",
    "\n",
    "CrossEntropyLoss: This is a common loss function used for classification tasks. It combines Softmax and Negative Log Likelihood loss.\n",
    "Adam: It's an optimization algorithm that can handle sparse gradients on noisy problems.\n",
    "\n",
    "# Training Loop:\n",
    "\n",
    "This is where the bulk of the learning happens:\n",
    "\n",
    "- model.train(): This tells the model that it's in training mode. This is essential because certain layers like dropout or batch normalization function differently during training and evaluation.\n",
    "\n",
    "- optimizer.zero_grad(): Before the backward pass, the gradients are set to zero.\n",
    "\n",
    "- outputs = model(inputs): Forward pass. It gets the predictions from the model for a batch of inputs.\n",
    "\n",
    "- loss = criterion(outputs, labels): Compute the loss between the predictions and true labels.\n",
    "\n",
    "- loss.backward(): Backward pass. Computes the gradient of the loss with respect to model parameters.\n",
    "\n",
    "- optimizer.step(): Adjusts each parameter in accordance with its gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Train Loss: 0.1013, Train Accuracy: 96.92%, Test Loss: 0.0487, Test Accuracy: 98.47%\n",
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         15085215 function calls (14997082 primitive calls) in 154.710 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "   118505  117.733    0.001  117.733    0.001 {method 'item' of 'torch._C._TensorBase' objects}\n",
      "    70000    8.652    0.000    8.652    0.000 {method 'resize' of 'ImagingCore' objects}\n",
      "    72190    3.423    0.000    3.423    0.000 {method 'to' of 'torch._C._TensorBase' objects}\n",
      "      938    2.339    0.002    2.339    0.002 {method 'run_backward' of 'torch._C._EngineBase' objects}\n",
      "    21900    1.530    0.000    1.530    0.000 {built-in method torch.conv2d}\n",
      "     1095    1.478    0.001    1.478    0.001 {built-in method torch.stack}\n",
      "    70000    1.128    0.000    1.128    0.000 {method 'div' of 'torch._C._TensorBase' objects}\n",
      "    70000    1.095    0.000    3.988    0.000 _functional_tensor.py:905(normalize)\n",
      "    70000    0.804    0.000   24.540    0.000 mnist.py:130(__getitem__)\n",
      "    70000    0.715    0.000    0.715    0.000 {method 'clone' of 'torch._C._TensorBase' objects}\n",
      "    70000    0.643    0.000    1.940    0.000 {built-in method numpy.array}\n",
      "    70000    0.634    0.000    5.959    0.000 functional.py:125(to_tensor)\n",
      "    21900    0.633    0.000    0.633    0.000 {built-in method torch.batch_norm}\n",
      "   140000    0.571    0.000    0.571    0.000 {built-in method torch.as_tensor}\n",
      "   210000    0.550    0.000    0.550    0.000 {method 'view' of 'torch._C._TensorBase' objects}\n",
      "    70000    0.524    0.000    0.524    0.000 {method 'sub_' of 'torch._C._TensorBase' objects}\n",
      "224315/142190    0.457    0.000   19.642    0.000 module.py:1494(_call_impl)\n",
      "    70000    0.449    0.000    0.449    0.000 {method 'div_' of 'torch._C._TensorBase' objects}\n",
      "   280000    0.407    0.000    0.684    0.000 utils.py:538(_log_api_usage_once)\n",
      "    70000    0.401    0.000    1.373    0.000 Image.py:3031(fromarray)\n",
      "    70000    0.352    0.000   10.680    0.000 functional.py:391(resize)\n",
      "    70000    0.298    0.000    0.953    0.000 Image.py:725(tobytes)\n",
      "    70000    0.288    0.000    0.288    0.000 {method 'numpy' of 'torch._C._TensorBase' objects}\n",
      "    70000    0.260    0.000    0.260    0.000 {method 'any' of 'torch._C._TensorBase' objects}\n",
      "    70000    0.259    0.000   22.076    0.000 transforms.py:93(__call__)\n",
      "    70000    0.258    0.000    9.162    0.000 Image.py:2090(resize)\n",
      "    70000    0.251    0.000    4.519    0.000 functional.py:340(normalize)\n",
      "   210000    0.249    0.000    0.360    0.000 Image.py:542(_new)\n",
      "    18760    0.246    0.000    0.246    0.000 {method 'add_' of 'torch._C._TensorBase' objects}\n",
      "    70000    0.246    0.000    0.246    0.000 {method 'permute' of 'torch._C._TensorBase' objects}\n",
      "1883865/1883726    0.233    0.000    0.241    0.000 {built-in method builtins.isinstance}\n",
      "     8760    0.226    0.000    2.663    0.000 resnet.py:89(forward)\n",
      "    18615    0.226    0.000    0.226    0.000 {built-in method torch.relu_}\n",
      "    70000    0.220    0.000    0.220    0.000 {method 'encode' of 'ImagingEncoder' objects}\n",
      "    70000    0.204    0.000    0.204    0.000 {built-in method torch.from_numpy}\n",
      "     1876    0.186    0.000    0.186    0.000 {built-in method torch._foreach_add_}\n",
      "   280002    0.184    0.000    0.184    0.000 {built-in method torch._C._log_api_usage_once}\n",
      "   224321    0.172    0.000    0.172    0.000 {built-in method torch._C._get_tracing_state}\n",
      "    70000    0.170    0.000    0.948    0.000 Image.py:2974(frombuffer)\n",
      "    70000    0.153    0.000    6.112    0.000 transforms.py:129(__call__)\n",
      "   280000    0.153    0.000    0.246    0.000 _trace.py:1101(is_tracing)\n",
      "    70000    0.151    0.000    0.225    0.000 Image.py:417(_getencoder)\n",
      "      938    0.142    0.000    0.168    0.000 _foreach_utils.py:20(_group_tensors_by_device_and_dtype)\n",
      "    21900    0.141    0.000    1.237    0.000 batchnorm.py:137(forward)\n",
      "   245426    0.140    0.000    0.140    0.000 module.py:1601(__getattr__)\n",
      "    70000    0.140    0.000    0.502    0.000 Image.py:2897(new)\n",
      "      938    0.140    0.000    0.181    0.000 adam.py:66(_init_group)\n",
      "        1    0.137    0.137  154.710  154.710 <string>:1(<module>)\n",
      "      938    0.136    0.000    0.186    0.000 optimizer.py:435(zero_grad)\n",
      "    70000    0.133    0.000    0.133    0.000 {built-in method PIL._imaging.fill}\n",
      "   280000    0.129    0.000    0.129    0.000 Image.py:511(__init__)\n",
      "   210000    0.126    0.000    0.165    0.000 Image.py:831(load)\n",
      "    70000    0.121    0.000    0.244    0.000 _functional_pil.py:22(get_dimensions)\n",
      "    70000    0.120    0.000    9.318    0.000 _functional_pil.py:238(resize)\n",
      "    70000    0.118    0.000    1.249    0.000 Image.py:686(__array_interface__)\n",
      "    70000    0.108    0.000    0.556    0.000 functional.py:64(get_dimensions)\n",
      "    70000    0.102    0.000    0.179    0.000 Image.py:249(_conv_type_shape)\n",
      "   140000    0.097    0.000    0.130    0.000 Image.py:2876(_check_size)\n",
      "   280000    0.092    0.000    0.113    0.000 _functional_pil.py:14(_is_pil_image)\n",
      "    70000    0.092    0.000    0.092    0.000 {built-in method PIL._imaging.map_buffer}\n",
      "990580/990568    0.086    0.000    0.086    0.000 {built-in method builtins.len}\n",
      "     1095    0.086    0.000    0.086    0.000 {built-in method torch.max}\n",
      "     2973    0.083    0.000    0.083    0.000 {built-in method torch._ops.profiler._record_function_enter_new}\n",
      "      938    0.082    0.000    0.082    0.000 {built-in method torch._foreach_sqrt}\n",
      "      938    0.081    0.000    0.081    0.000 {built-in method torch._foreach_add}\n",
      "   140000    0.078    0.000    0.116    0.000 Image.py:1308(getbands)\n",
      "   280000    0.073    0.000    0.073    0.000 {built-in method torch._C._is_tracing}\n",
      "    70000    0.073    0.000   10.753    0.000 transforms.py:353(forward)\n",
      "   700000    0.072    0.000    0.072    0.000 Image.py:538(size)\n",
      "    70000    0.071    0.000    0.177    0.000 _functional_pil.py:41(get_image_num_channels)\n",
      "   280008    0.068    0.000    0.068    0.000 {method 'startswith' of 'str' objects}\n",
      "     1095    0.067    0.000    0.067    0.000 {built-in method torch._C._nn.linear}\n",
      "   116312    0.065    0.000    0.121    0.000 optimizer.py:39(_get_value)\n",
      "   742132    0.059    0.000    0.059    0.000 _jit_internal.py:1102(is_scripting)\n",
      "      938    0.058    0.000    1.102    0.001 adam.py:231(adam)\n",
      "   232624    0.058    0.000    0.058    0.000 {built-in method torch.is_complex}\n",
      "    21900    0.058    0.000    0.767    0.000 functional.py:2419(batch_norm)\n",
      "   210000    0.057    0.000    0.057    0.000 ImageMode.py:36(getmode)\n",
      "     1095    0.055    0.000   24.596    0.022 fetch.py:51(<listcomp>)\n",
      "     1097    0.053    0.000   26.273    0.024 dataloader.py:675(_next_data)\n",
      "     1095    0.049    0.000    0.049    0.000 {method 'sum' of 'torch._C._TensorBase' objects}\n",
      "    70000    0.049    0.000    4.568    0.000 transforms.py:269(forward)\n",
      "    70000    0.047    0.000    0.047    0.000 Image.py:524(__getattr__)\n",
      "   652506    0.046    0.000    0.046    0.000 {method 'append' of 'list' objects}\n",
      "   140000    0.044    0.000    0.058    0.000 Image.py:530(width)\n",
      "    21900    0.043    0.000    1.623    0.000 conv.py:462(forward)\n",
      "     1876    0.043    0.000    0.043    0.000 {built-in method torch._foreach_mul_}\n",
      "     1095    0.042    0.000    0.042    0.000 {built-in method torch._C._nn.cross_entropy_loss}\n",
      "    70000    0.040    0.000    0.040    0.000 _functional_tensor.py:9(_is_tensor_a_torch_image)\n",
      "    70000    0.040    0.000    0.040    0.000 {built-in method PIL._imaging.raw_encoder}\n",
      "   140000    0.039    0.000    0.052    0.000 Image.py:534(height)\n",
      "   210000    0.039    0.000    0.039    0.000 {method 'pixel_access' of 'ImagingCore' objects}\n",
      "     1157    0.035    0.000    0.035    0.000 {built-in method torch.tensor}\n",
      "    18760    0.035    0.000    0.038    0.000 functional.py:2402(_verify_batch_size)\n",
      "    70000    0.033    0.000    0.038    0.000 functional.py:366(_compute_resized_output_size)\n",
      "    21900    0.033    0.000    1.563    0.000 conv.py:454(_conv_forward)\n",
      "     2973    0.033    0.000    0.033    0.000 {built-in method torch._ops.profiler.}\n",
      "    70000    0.033    0.000    0.050    0.000 functional.py:1596(_check_antialias)\n",
      "   144070    0.032    0.000    0.032    0.000 {built-in method builtins.hasattr}\n",
      "    58156    0.031    0.000    0.046    0.000 optimizer.py:52(_dispatch_sqrt)\n",
      "      938    0.031    0.000    0.031    0.000 {built-in method torch._foreach_addcdiv_}\n",
      "     1095    0.031    0.000    3.871    0.004 resnet.py:266(_forward_impl)\n",
      "     1095    0.029    0.000    0.029    0.000 {built-in method torch._C._nn.adaptive_avg_pool2d}\n",
      "    70000    0.029    0.000    0.029    0.000 {built-in method builtins.max}\n",
      "      938    0.028    0.000    0.028    0.000 {built-in method torch._foreach_div_}\n",
      "      938    0.027    0.000    0.027    0.000 {built-in method torch._foreach_addcmul_}\n",
      "     2973    0.027    0.000    0.065    0.000 profiler.py:495(__exit__)\n",
      "    70000    0.027    0.000    0.027    0.000 {method 'contiguous' of 'torch._C._TensorBase' objects}\n",
      "    72823    0.026    0.000    0.026    0.000 {built-in method builtins.getattr}\n",
      "    70000    0.026    0.000    0.026    0.000 {method 'setimage' of 'ImagingEncoder' objects}\n",
      "    70000    0.026    0.000    0.035    0.000 functional.py:115(_is_numpy)\n",
      "    70000    0.025    0.000    0.066    0.000 _functional_tensor.py:13(_assert_image_tensor)\n",
      "    70000    0.025    0.000    0.025    0.000 {built-in method torch.get_default_dtype}\n",
      "     1095    0.025    0.000    0.025    0.000 {built-in method torch.max_pool2d}\n",
      "    70000    0.024    0.000    0.033    0.000 enum.py:1226(__hash__)\n",
      "   210000    0.024    0.000    0.024    0.000 {method 'copy' of 'dict' objects}\n",
      "3285/1095    0.024    0.000    1.586    0.001 collate.py:87(collate)\n",
      "7665/4380    0.024    0.000    2.711    0.001 container.py:215(forward)\n",
      "    70000    0.023    0.000    0.023    0.000 {method 'is_floating_point' of 'torch._C._TensorBase' objects}\n",
      "   141417    0.021    0.000    0.021    0.000 {method 'get' of 'dict' objects}\n",
      "     1097    0.020    0.000   26.394    0.024 dataloader.py:628(__next__)\n",
      "      938    0.020    0.000    0.086    0.000 adam.py:489(<listcomp>)\n",
      "      938    0.019    0.000    0.994    0.001 adam.py:396(_multi_tensor_adam)\n",
      "    59094    0.019    0.000    0.019    0.000 optimizer.py:72(<genexpr>)\n",
      "    20950    0.018    0.000    0.018    0.000 {method 'size' of 'torch._C._TensorBase' objects}\n",
      "      938    0.018    0.000    0.018    0.000 {built-in method torch.ones_like}\n",
      "     2973    0.018    0.000    0.026    0.000 profiler.py:482(__init__)\n",
      "      938    0.017    0.000    1.398    0.001 optimizer.py:265(wrapper)\n",
      "     3909    0.017    0.000    0.070    0.000 {built-in method builtins.all}\n",
      "    18615    0.015    0.000    0.246    0.000 functional.py:1446(relu)\n",
      "      938    0.015    0.000    0.070    0.000 adam.py:490(<listcomp>)\n",
      "     1097    0.015    0.000    0.024    0.000 sampler.py:241(__iter__)\n",
      "    70000    0.015    0.000    0.018    0.000 collate.py:137(<genexpr>)\n",
      "    18615    0.014    0.000    0.261    0.000 activation.py:102(forward)\n",
      "     2973    0.014    0.000    0.102    0.000 profiler.py:491(__enter__)\n",
      "    21900    0.013    0.000    0.024    0.000 batchnorm.py:408(_check_input_dim)\n",
      "     1095    0.013    0.000    0.013    0.000 {built-in method torch.flatten}\n",
      "    70000    0.013    0.000    0.013    0.000 {method 'join' of 'bytes' objects}\n",
      "    59094    0.013    0.000    0.016    0.000 adam.py:268(<genexpr>)\n",
      "      938    0.011    0.000    0.026    0.000 adam.py:433(<listcomp>)\n",
      "    58466    0.011    0.000    0.017    0.000 _tensor.py:942(__hash__)\n",
      "    21906    0.010    0.000    0.010    0.000 {method 'dim' of 'torch._C._TensorBase' objects}\n",
      "    22995    0.010    0.000    0.010    0.000 {built-in method torch._C._has_torch_function_variadic}\n",
      "      938    0.010    0.000    0.055    0.000 adam.py:494(<listcomp>)\n",
      "      938    0.010    0.000    0.025    0.000 adam.py:434(<listcomp>)\n",
      "      938    0.009    0.000    1.336    0.001 optimizer.py:29(_use_grad)\n",
      "      938    0.009    0.000    0.021    0.000 adam.py:436(<listcomp>)\n",
      "      938    0.009    0.000    0.025    0.000 adam.py:435(<listcomp>)\n",
      "    70002    0.009    0.000    0.009    0.000 {built-in method builtins.hash}\n",
      "      938    0.009    0.000    1.321    0.001 adam.py:108(step)\n",
      "     7665    0.008    0.000    0.013    0.000 container.py:207(__iter__)\n",
      "    21900    0.008    0.000    0.014    0.000 __init__.py:31(__get__)\n",
      "      938    0.008    0.000    2.374    0.003 __init__.py:106(backward)\n",
      "2974/2973    0.008    0.000    0.008    0.000 typing.py:345(inner)\n",
      "      938    0.007    0.000    2.382    0.003 _tensor.py:428(backward)\n",
      "   117250    0.007    0.000    0.007    0.000 _utils.py:786(is_compiling)\n",
      "     1095    0.007    0.000    0.009    0.000 utils.py:33(_list_with_default)\n",
      "      938    0.006    0.000    0.025    0.000 __init__.py:50(_make_grads)\n",
      "     1095    0.006    0.000   26.194    0.024 fetch.py:46(fetch)\n",
      "     1095    0.006    0.000    1.484    0.001 collate.py:153(collate_tensor_fn)\n",
      "    21749    0.006    0.000    0.006    0.000 {built-in method torch._C._has_torch_function_unary}\n",
      "    60001    0.006    0.000    0.009    0.000 sampler.py:117(__iter__)\n",
      "    21900    0.006    0.000    0.006    0.000 {built-in method torch._C._get_cudnn_enabled}\n",
      "     3754    0.005    0.000    0.007    0.000 grad_mode.py:149(__init__)\n",
      "    58466    0.005    0.000    0.005    0.000 {built-in method builtins.id}\n",
      "    58156    0.005    0.000    0.005    0.000 {built-in method math.sqrt}\n",
      "     1095    0.005    0.000    1.532    0.001 collate.py:142(<listcomp>)\n",
      "      938    0.005    0.000    0.007    0.000 <frozen os>:674(__getitem__)\n",
      "     2973    0.005    0.000    0.088    0.000 _ops.py:497(__call__)\n",
      "      938    0.005    0.000    0.005    0.000 {built-in method torch._C._cuda_isCurrentStreamCapturing}\n",
      "     2973    0.005    0.000    0.037    0.000 _ops.py:286(__call__)\n",
      "     1095    0.004    0.000    0.052    0.000 loss.py:1173(forward)\n",
      "      938    0.004    0.000    0.029    0.000 optimizer.py:228(_cuda_graph_capture_health_check)\n",
      "      938    0.004    0.000    0.004    0.000 adam.py:492(<listcomp>)\n",
      "     1095    0.004    0.000    0.043    0.000 functional.py:1200(adaptive_avg_pool2d)\n",
      "     1095    0.004    0.000    0.033    0.000 pooling.py:165(forward)\n",
      "      938    0.004    0.000    0.181    0.000 _contextlib.py:112(decorate_context)\n",
      "      939    0.004    0.000    0.004    0.000 grad_mode.py:48(__init__)\n",
      "     1095    0.003    0.000    1.590    0.001 collate.py:204(default_collate)\n",
      "     2196    0.003    0.000    0.007    0.000 {built-in method _abc._abc_instancecheck}\n",
      "     8763    0.003    0.000    0.003    0.000 {built-in method builtins.iter}\n",
      "     1095    0.003    0.000    0.046    0.000 functional.py:2939(cross_entropy)\n",
      "      938    0.003    0.000    0.028    0.000 optimizer.py:64(_default_to_fused_or_foreach)\n",
      "     1095    0.003    0.000    0.071    0.000 linear.py:113(forward)\n",
      "     1095    0.003    0.000    0.030    0.000 _jit_internal.py:474(fn)\n",
      "      938    0.003    0.000    0.014    0.000 __init__.py:91(_nvml_based_avail)\n",
      "      938    0.003    0.000    0.003    0.000 _foreach_utils.py:24(<listcomp>)\n",
      "      938    0.002    0.000    0.019    0.000 __init__.py:94(is_available)\n",
      "      938    0.002    0.000    0.010    0.000 <frozen _collections_abc>:771(get)\n",
      "     1095    0.002    0.000    0.037    0.000 collate.py:182(collate_int_fn)\n",
      "    11418    0.002    0.000    0.002    0.000 {method 'values' of 'collections.OrderedDict' objects}\n",
      "     5631    0.002    0.000    0.002    0.000 {built-in method torch.is_grad_enabled}\n",
      "     1095    0.002    0.000    0.003    0.000 {built-in method _abc._abc_subclasscheck}\n",
      "     1095    0.002    0.000    0.045    0.000 pooling.py:1195(forward)\n",
      "     1095    0.002    0.000    0.027    0.000 functional.py:760(_max_pool2d)\n",
      "        2    0.002    0.001    0.002    0.001 {method 'tolist' of 'torch._C._TensorBase' objects}\n",
      "      938    0.002    0.000    0.002    0.000 <frozen os>:756(encode)\n",
      "     2192    0.002    0.000    0.026    0.000 {built-in method builtins.next}\n",
      "      938    0.002    0.000    0.011    0.000 <frozen os>:773(getenv)\n",
      "     1095    0.002    0.000    3.873    0.004 resnet.py:284(forward)\n",
      "     1097    0.002    0.000    0.027    0.000 dataloader.py:622(_next_index)\n",
      "      938    0.002    0.000    0.002    0.000 __init__.py:87(_is_compiled)\n",
      "      938    0.002    0.000    0.005    0.000 _contextlib.py:141(clone)\n",
      "      938    0.001    0.000    0.002    0.000 _foreach_utils.py:27(<lambda>)\n",
      "      939    0.001    0.000    0.003    0.000 grad_mode.py:53(__enter__)\n",
      "      943    0.001    0.000    0.001    0.000 {method 'format' of 'str' objects}\n",
      "     2196    0.001    0.000    0.008    0.000 <frozen abc>:117(__instancecheck__)\n",
      "      124    0.001    0.000    0.001    0.000 {built-in method torch.zeros_like}\n",
      "     1095    0.001    0.000    0.001    0.000 utils.py:40(<listcomp>)\n",
      "     1095    0.001    0.000    0.001    0.000 <frozen _collections_abc>:315(__subclasshook__)\n",
      "      939    0.001    0.000    0.002    0.000 grad_mode.py:57(__exit__)\n",
      "     3754    0.001    0.000    0.001    0.000 {built-in method torch._C._set_grad_enabled}\n",
      "        2    0.001    0.000    0.001    0.000 {built-in method torch.randperm}\n",
      "      938    0.001    0.000    0.001    0.000 {built-in method torch._C._are_functorch_transforms_active}\n",
      "      938    0.001    0.000    0.001    0.000 {built-in method torch._C._cuda_getDeviceCount}\n",
      "      938    0.001    0.000    0.001    0.000 _foreach_utils.py:27(<listcomp>)\n",
      "      938    0.001    0.000    0.005    0.000 graphs.py:19(is_current_stream_capturing)\n",
      "      938    0.001    0.000    0.001    0.000 {method 'numel' of 'torch._C._TensorBase' objects}\n",
      "     1095    0.001    0.000    0.001    0.000 _reduction.py:7(get_enum)\n",
      "      938    0.001    0.000    0.001    0.000 __init__.py:98(_tensor_or_tensors_to_tuple)\n",
      "     2973    0.001    0.000    0.001    0.000 {method '__exit__' of 'torch._C.DisableTorchFunctionSubclass' objects}\n",
      "     1095    0.001    0.000    0.004    0.000 <frozen abc>:121(__subclasscheck__)\n",
      "      938    0.001    0.000    0.001    0.000 {method 'encode' of 'str' objects}\n",
      "      938    0.001    0.000    0.001    0.000 optimizer.py:46(_stack_if_compiling)\n",
      "     1095    0.000    0.000    0.000    0.000 worker.py:89(get_worker_info)\n",
      "     2973    0.000    0.000    0.000    0.000 __init__.py:89(annotate)\n",
      "      938    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}\n",
      "        1    0.000    0.000  154.710  154.710 {built-in method builtins.exec}\n",
      "      139    0.000    0.000    0.000    0.000 module.py:1617(__setattr__)\n",
      "      938    0.000    0.000    0.000    0.000 optimizer.py:249(_optimizer_step_code)\n",
      "    136/2    0.000    0.000    0.001    0.000 module.py:2269(train)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method torch.empty}\n",
      "   315/69    0.000    0.000    0.000    0.000 module.py:2224(named_modules)\n",
      "      270    0.000    0.000    0.000    0.000 module.py:2176(named_children)\n",
      "       63    0.000    0.000    0.000    0.000 module.py:2045(_named_members)\n",
      "      270    0.000    0.000    0.000    0.000 module.py:2167(children)\n",
      "        3    0.000    0.000    0.000    0.000 {method 'random_' of 'torch._C._TensorBase' objects}\n",
      "      139    0.000    0.000    0.000    0.000 parameter.py:8(__instancecheck__)\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:489(add_param_group)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._get_operation_overload}\n",
      "        2    0.000    0.000    0.000    0.000 dataloader.py:567(__init__)\n",
      "      264    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}\n",
      "        6    0.000    0.000    0.000    0.000 _tensor.py:904(__len__)\n",
      "       68    0.000    0.000    0.000    0.000 module.py:2113(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 _ops.py:239(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 _ops.py:447(__getattr__)\n",
      "        1    0.000    0.000    0.000    0.000 socket.py:621(send)\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:169(__init__)\n",
      "      272    0.000    0.000    0.000    0.000 {method 'items' of 'collections.OrderedDict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.compile}\n",
      "        1    0.000    0.000    0.000    0.000 iostream.py:202(schedule)\n",
      "       63    0.000    0.000    0.000    0.000 module.py:2059(parameters)\n",
      "        1    0.000    0.000    0.000    0.000 module.py:437(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:518(write)\n",
      "       63    0.000    0.000    0.000    0.000 module.py:2084(named_parameters)\n",
      "        2    0.000    0.000    0.000    0.000 dataloader.py:661(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 typing.py:168(_type_check)\n",
      "      139    0.000    0.000    0.000    0.000 {function _ParameterMeta.__instancecheck__ at 0x7fd2b93b7380}\n",
      "        1    0.000    0.000    0.000    0.000 loss.py:20(__init__)\n",
      "       33    0.000    0.000    0.000    0.000 ImageMode.py:25(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:645(Union)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.print}\n",
      "        2    0.000    0.000    0.000    0.000 dataloader.py:74(create_fetcher)\n",
      "        7    0.000    0.000    0.000    0.000 typing.py:1284(__setattr__)\n",
      "        2    0.000    0.000    0.000    0.000 dataloader.py:459(__len__)\n",
      "        7    0.000    0.000    0.000    0.000 typing.py:1233(_is_dunder)\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:1340(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:291(_patch_step_function)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._get_schema}\n",
      "        1    0.000    0.000    0.000    0.000 adam.py:14(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 loss.py:29(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 dataloader.py:383(_get_iterator)\n",
      "        2    0.000    0.000    0.000    0.000 dataloader.py:98(_get_distributed_settings)\n",
      "        6    0.000    0.000    0.000    0.000 mnist.py:152(__len__)\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:685(Optional)\n",
      "        1    0.000    0.000    0.000    0.000 module.py:480(register_buffer)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:1185(is_alive)\n",
      "        3    0.000    0.000    0.000    0.000 typing.py:159(_type_convert)\n",
      "        2    0.000    0.000    0.000    0.000 sampler.py:264(__len__)\n",
      "      2/1    0.000    0.000    0.000    0.000 typing.py:468(__getitem__)\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:262(profile_hook_step)\n",
      "        1    0.000    0.000    0.000    0.000 functools.py:35(update_wrapper)\n",
      "        1    0.000    0.000    0.000    0.000 loss.py:1167(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 distributed_c10d.py:683(is_initialized)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:448(_schedule_flush)\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:308(_remove_dups_flatten)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:429(_is_master_process)\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:825(__init__)\n",
      "       17    0.000    0.000    0.000    0.000 typing.py:875(__eq__)\n",
      "        2    0.000    0.000    0.000    0.000 dataloader.py:428(__iter__)\n",
      "        2    0.000    0.000    0.000    0.000 distributed_c10d.py:403(WORLD)\n",
      "        4    0.000    0.000    0.000    0.000 dataloader.py:447(_index_sampler)\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method builtins.setattr}\n",
      "        2    0.000    0.000    0.000    0.000 __init__.py:7(is_available)\n",
      "        6    0.000    0.000    0.000    0.000 dataloader.py:443(_auto_collation)\n",
      "        3    0.000    0.000    0.000    0.000 sampler.py:110(num_samples)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'manual_seed' of 'torch._C.Generator' objects}\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:1245(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 iostream.py:90(_event_pipe)\n",
      "        1    0.000    0.000    0.000    0.000 sampler.py:75(__iter__)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:1118(_wait_for_tstate_lock)\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:245(_collect_parameters)\n",
      "        2    0.000    0.000    0.000    0.000 typing.py:884(__hash__)\n",
      "       10    0.000    0.000    0.000    0.000 {method 'setdefault' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:294(_deduplicate)\n",
      "        2    0.000    0.000    0.000    0.000 fetch.py:8(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 module.py:2291(eval)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 sampler.py:78(__len__)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
      "        3    0.000    0.000    0.000    0.000 typing.py:677(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 functools.py:65(wraps)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}\n",
      "        2    0.000    0.000    0.000    0.000 distributed_c10d.py:323(default_pg)\n",
      "        1    0.000    0.000    0.000    0.000 sampler.py:135(__len__)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:447(__repr__)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "        3    0.000    0.000    0.000    0.000 typing.py:1345(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'discard' of 'set' objects}\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:568(is_set)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'isdisjoint' of 'set' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}"
     ]
    }
   ],
   "source": [
    "%%prun # Profiler para medir tempos\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    model.train()\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    train_losses.append(train_loss / len(train_loader))\n",
    "    train_accuracies.append(100 * correct_train / total_train)\n",
    "\n",
    "    test_loss = 0.0\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_test += labels.size(0)\n",
    "            correct_test += (predicted == labels).sum().item()\n",
    "    \n",
    "    test_losses.append(test_loss / len(test_loader))\n",
    "    test_accuracies.append(100 * correct_test / total_test)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, '\n",
    "          f'Train Loss: {train_losses[-1]:.4f}, Train Accuracy: {train_accuracies[-1]:.2f}%, '\n",
    "          f'Test Loss: {test_losses[-1]:.4f}, Test Accuracy: {test_accuracies[-1]:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fonta42/anaconda3/envs/torchtrainer/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"orientation\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/home/fonta42/anaconda3/envs/torchtrainer/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"facecolor\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/home/fonta42/anaconda3/envs/torchtrainer/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"edgecolor\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/home/fonta42/anaconda3/envs/torchtrainer/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"bbox_inches_restore\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(test_losses, label='Testing Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Training Accuracy')\n",
    "plt.plot(test_accuracies, label='Testing Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "\n",
    "_ = plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Loop:\n",
    "\n",
    "Here, the performance of the model is evaluated:\n",
    "\n",
    "- model.eval(): Switches the model to evaluation mode.\n",
    "\n",
    "Since we're only evaluating the model, we use torch.no_grad(). This is because we don't need to compute gradients, which saves memory and computation.\n",
    "The rest of the loop is similar to the training loop, but without the backpropagation and optimization steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 10000 test images: 98.47%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the model on the 10000 test images: {100 * correct / total}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model's state_dict\n",
    "torch.save(model.state_dict(), './Models/resnet18_mnist.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchtrainer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
