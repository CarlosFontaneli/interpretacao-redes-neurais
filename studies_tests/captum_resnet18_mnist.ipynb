{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mOSError: [Errno 28] No space left on device. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from captum.attr import IntegratedGradients\n",
    "from captum.attr import GradientShap\n",
    "from captum.attr import Occlusion\n",
    "from captum.attr import NoiseTunnel\n",
    "from captum.attr import visualization as viz\n",
    "\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mOSError: [Errno 28] No space left on device. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Default device plus free memory\n",
    "torch.cuda.empty_cache()\n",
    "device = \"cpu\"\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mOSError: [Errno 28] No space left on device. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Modify ResNet-18 for MNIST\n",
    "model = resnet18(pretrained=False)\n",
    "# Change the input layer to accept grayscale images\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "# Adjust the final layer to output 10 classes\n",
    "model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "\n",
    "# Load the saved state_dict\n",
    "model.load_state_dict(torch.load('./Models/resnet18_mnist.pth'))\n",
    "\n",
    "# Move model to device and set to evaluation mode\n",
    "model = model.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mOSError: [Errno 28] No space left on device. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Apply resize and normalization to the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Download the MNIST dataset\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mOSError: [Errno 28] No space left on device. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Fetch an image and its label\n",
    "image, label = test_dataset[0]  # This fetches the first image from the test set\n",
    "\n",
    "plt.imshow(image.squeeze(), cmap='gray')  # Since it's a grayscale image\n",
    "plt.title(f\"True Label: {label}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mOSError: [Errno 28] No space left on device. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Add batch dimension and run the model\n",
    "with torch.no_grad():\n",
    "    image = image.unsqueeze(0).to(device)  # Add batch dimension\n",
    "    output = model(image)\n",
    "    predicted_label = torch.argmax(output).item()\n",
    "    probabilities = F.softmax(output, dim=1)  # Apply softmax to get the probabilities\n",
    "    prediction_score = probabilities[0][predicted_label].item()  # Confidence score for the predicted label\n",
    "\n",
    "print(f\"Predicted Label: {predicted_label}\")\n",
    "print(f\"Confidence Score for the Predicted Label: {prediction_score:.4f}\")\n",
    "print(f\"Probability Distribution over Classes: {probabilities[0].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mOSError: [Errno 28] No space left on device. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "pred_label_idx = predicted_label\n",
    "transformed_img = image\n",
    "\n",
    "integrated_gradients = IntegratedGradients(model)\n",
    "attributions_ig = integrated_gradients.attribute(transformed_img, target=predicted_label, n_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mOSError: [Errno 28] No space left on device. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(attributions_ig.squeeze().cpu().detach().numpy().shape)\n",
    "transformed_img.squeeze().cpu().detach().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mOSError: [Errno 28] No space left on device. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import numpy as np\n",
    "\n",
    "default_cmap = LinearSegmentedColormap.from_list(\n",
    "    'custom blue', \n",
    "    [(0, '#ffffff'),\n",
    "     (0.25, '#000000'),\n",
    "     (1, '#000000')],\n",
    "    N=256\n",
    ")\n",
    "\n",
    "attr_reshaped = attributions_ig.squeeze().cpu().detach().numpy().reshape(224, 224, 1)\n",
    "img_reshaped = transformed_img.squeeze().cpu().detach().numpy().reshape(224, 224, 1)\n",
    "\n",
    "_ = viz.visualize_image_attr(attr_reshaped,\n",
    "                             img_reshaped,\n",
    "                             method='heat_map',\n",
    "                             cmap=default_cmap,\n",
    "                             show_colorbar=True,\n",
    "                             sign='positive',\n",
    "                             outlier_perc=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mOSError: [Errno 28] No space left on device. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "noise_tunnel = NoiseTunnel(integrated_gradients)\n",
    "input = image\n",
    "\n",
    "attributions_ig_nt = noise_tunnel.attribute(input, nt_samples=10, nt_type='smoothgrad_sq', target=predicted_label)\n",
    "_ = viz.visualize_image_attr_multiple(attr_reshaped,\n",
    "                                      img_reshaped,\n",
    "                                      [\"original_image\", \"heat_map\"],\n",
    "                                      [\"all\", \"positive\"],\n",
    "                                      cmap=default_cmap,\n",
    "                                      show_colorbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mOSError: [Errno 28] No space left on device. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "input = image\n",
    "\n",
    "gradient_shap = GradientShap(model)\n",
    "\n",
    "# Defining baseline distribution of images\n",
    "rand_img_dist = torch.cat([input * 0, input * 1])\n",
    "\n",
    "attributions_gs = gradient_shap.attribute(input,\n",
    "                                          n_samples=50,\n",
    "                                          stdevs=0.0001,\n",
    "                                          baselines=rand_img_dist,\n",
    "                                          target=pred_label_idx)\n",
    "_ = viz.visualize_image_attr_multiple(attr_reshaped,\n",
    "                                      img_reshaped,\n",
    "                                      [\"original_image\", \"heat_map\"],\n",
    "                                      [\"all\", \"absolute_value\"],\n",
    "                                      cmap=default_cmap,\n",
    "                                      show_colorbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mOSError: [Errno 28] No space left on device. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "occlusion = Occlusion(model)\n",
    "\n",
    "attributions_occ = occlusion.attribute(input,\n",
    "                                       strides = (1, 8, 8),\n",
    "                                       target=pred_label_idx,\n",
    "                                       sliding_window_shapes=(1,16, 16),\n",
    "                                       baselines=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mOSError: [Errno 28] No space left on device. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "_ = viz.visualize_image_attr_multiple(attr_reshaped,\n",
    "                                      img_reshaped,\n",
    "                                      [\"original_image\", \"heat_map\"],\n",
    "                                      [\"all\", \"positive\"],\n",
    "                                      show_colorbar=True,\n",
    "                                      outlier_perc=2,\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mOSError: [Errno 28] No space left on device. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "occlusion = Occlusion(model)\n",
    "\n",
    "attributions_occ = occlusion.attribute(input,\n",
    "                                       strides = (1, 48, 48),\n",
    "                                       target=pred_label_idx,\n",
    "                                       sliding_window_shapes=(1,80, 80),\n",
    "                                       baselines=0)\n",
    "\n",
    "_ = viz.visualize_image_attr_multiple(attr_reshaped,\n",
    "                                      img_reshaped,\n",
    "                                      [\"original_image\", \"heat_map\"],\n",
    "                                      [\"all\", \"positive\"],\n",
    "                                      show_colorbar=True,\n",
    "                                      outlier_perc=2,\n",
    "                                     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchtrainer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
